{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e55c2c6566646eba645c3dd83f0c0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a83eccf4995f468e865fd1d425e871ea",
              "IPY_MODEL_98f4b440247e428fbddda910a497b83b",
              "IPY_MODEL_6e8a79ff40f44df3bf89d00615b20a02"
            ],
            "layout": "IPY_MODEL_21ad88caacc447068f48d7fe840e4e2e"
          }
        },
        "a83eccf4995f468e865fd1d425e871ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681e0c18c8d945b99754a2a7e3efea60",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e5070f9c1ecf4afb91b9a6ff68295f56",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "98f4b440247e428fbddda910a497b83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d1efd1e4edb46469d3c59840ad3ea81",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_907c576b14e04123be0856fe81f25337",
            "value": 2
          }
        },
        "6e8a79ff40f44df3bf89d00615b20a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_325b1d7adf5b40e59b7464509403cd33",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b9b227b7303c4d6a8d507a49b8a1a8fa",
            "value": "‚Äá2/2‚Äá[00:26&lt;00:00,‚Äá12.06s/it]"
          }
        },
        "21ad88caacc447068f48d7fe840e4e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681e0c18c8d945b99754a2a7e3efea60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5070f9c1ecf4afb91b9a6ff68295f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d1efd1e4edb46469d3c59840ad3ea81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "907c576b14e04123be0856fe81f25337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "325b1d7adf5b40e59b7464509403cd33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b227b7303c4d6a8d507a49b8a1a8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Overview\n",
        "\n",
        "In this notebook, I will develop a chatbot app that generates datasets to the user's request.\n",
        "\n",
        "The LLM model that will be used in this app is `Llama-3.2-3B-Instruct`, which can easily be replaced with other models in the pipeline below."
      ],
      "metadata": {
        "id": "It89APiAtTUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "M-mTmXz9USNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bcc86c-b08a-403e-8abb-253435b07f17"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FW8nl3XRFrz0"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig, TextIteratorStreamer\n",
        "import torch\n",
        "import pandas as pd\n",
        "import io\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "\n",
        "LLAMA = \"meta-llama/Llama-3.2-3B-Instruct\""
      ],
      "metadata": {
        "id": "q3D1_T0uG_Qh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sign in to HuggingFace Hub\n",
        "\n",
        "## To access the model, you must have a Hugging Face token and use it to login and access the Llama model.\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)\n"
      ],
      "metadata": {
        "id": "xYW8kQYtF-3L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Setting the model and tokenizer"
      ],
      "metadata": {
        "id": "2GLpveo8cgzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)\n"
      ],
      "metadata": {
        "id": "bL0QLmsKh2vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Running an Example"
      ],
      "metadata": {
        "id": "mX0N77VyjA7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "system_message = \"\"\"\n",
        "You receive information from the user about generating a dataset.\n",
        "The information includes:\n",
        "1. the columns of the dataset (names and meanings).\n",
        "2. number of rows (20 unless the user specified otherwise).\n",
        "\n",
        "if the user's prompt does not meet the requirements - ask the user to follow the instructions.\n",
        "otherwise, you should answer directly with the table, as a markdown table.\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_message}\n",
        "  ]\n",
        "\n",
        "user_prompt = \"\"\"\n",
        "please generate me a dataset of users, including the next columns:\n",
        "id, user_name, password, rank.\n",
        "please generate 5 rows only.\n",
        "\"\"\"\n",
        "{\"role\": \"user\", \"content\": user_prompt}\n",
        "messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
        "\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
        "streamer = TextStreamer(tokenizer)\n",
        "outputs = model.generate(inputs, max_new_tokens=2000, streamer=streamer)\n",
        "response = tokenizer.decode(outputs[0])\n",
        "\n",
        "response = tokenizer.decode(outputs[0]).split(\"assistant<|end_header_id|>\")[1]\n",
        "\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "id": "UcRKUgcxMew6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555,
          "referenced_widgets": [
            "1e55c2c6566646eba645c3dd83f0c0d8",
            "a83eccf4995f468e865fd1d425e871ea",
            "98f4b440247e428fbddda910a497b83b",
            "6e8a79ff40f44df3bf89d00615b20a02",
            "21ad88caacc447068f48d7fe840e4e2e",
            "681e0c18c8d945b99754a2a7e3efea60",
            "e5070f9c1ecf4afb91b9a6ff68295f56",
            "3d1efd1e4edb46469d3c59840ad3ea81",
            "907c576b14e04123be0856fe81f25337",
            "325b1d7adf5b40e59b7464509403cd33",
            "b9b227b7303c4d6a8d507a49b8a1a8fa"
          ]
        },
        "outputId": "63b07033-26c9-41ec-a4c4-87e14b8b0cda"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e55c2c6566646eba645c3dd83f0c0d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 29 Dec 2025\n",
            "\n",
            "You receive information from the user about generating a dataset. \n",
            "The information includes: \n",
            "1. the columns of the dataset (names and meanings).\n",
            "2. number of rows (20 unless the user specified otherwise).\n",
            "\n",
            "if the user's prompt does not meet the requirements - ask the user to follow the instructions.\n",
            "otherwise, you should answer directly with the table, as a markdown table.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "please generate me a dataset of users, including the next columns: \n",
            "id, user_name, password, rank.\n",
            "please generate 5 rows only.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Here is the generated dataset as a markdown table:\n",
            "\n",
            "| id | user_name | password | rank |\n",
            "|----|-----------|----------|------|\n",
            "| 1  | John       | password1 | 1     |\n",
            "| 2  | Alice       | password2 | 2     |\n",
            "| 3  | Bob        | password3 | 3     |\n",
            "| 4  | Jane       | password4 | 4     |\n",
            "| 5  | Mike       | password5 | 5     |<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Building a gradio app"
      ],
      "metadata": {
        "id": "2QA44ldojXBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from threading import Thread\n",
        "\n",
        "\n",
        "SYSTEM_MESSAGE = \"\"\"\n",
        "You receive information from the user about generating a dataset.\n",
        "The information includes:\n",
        "1. the columns of the dataset (names and meanings).\n",
        "2. number of rows (20 unless the user specified otherwise).\n",
        "\n",
        "if the user's prompt does not meet the requirements - ask the user to follow the instructions.\n",
        "otherwise, you should answer directly with the table, as a markdown table.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def extract_table_to_csv(history):\n",
        "    \"\"\"Parses the last assistant message for a markdown table and saves to CSV.\"\"\"\n",
        "    if not history:\n",
        "        return None\n",
        "\n",
        "    # Get the last message from the assistant\n",
        "    last_message = history[-1][\"content\"]\n",
        "\n",
        "    # Simple regex to find a markdown table (starts and ends with |)\n",
        "    table_match = re.search(r'(\\|.*\\|(?:\\n\\|.*\\|)+)', last_message)\n",
        "    if not table_match:\n",
        "        return None\n",
        "\n",
        "    table_str = table_match.group(1)\n",
        "    # Remove the <|eot_id|> token if it's appended to the last line of the table.\n",
        "    # This happens because the model output includes this token after the generated table.\n",
        "    table_str = table_str.replace('<|eot_id|', '').strip()\n",
        "\n",
        "    # Use pandas to read the markdown table\n",
        "    # We clean the string to remove the '---' separator line which can confuse basic parsers\n",
        "    lines = [line for line in table_str.split('\\n') if '---|' not in line and line.strip()]\n",
        "    df = pd.read_csv(io.StringIO('\\n'.join(lines)), sep='|', skipinitialspace=True).dropna(axis=1, how='all')\n",
        "\n",
        "    # Clean column names and data (removing whitespace)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    df = df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "    # Save to a temporary CSV\n",
        "    file_path = \"generated_dataset.csv\"\n",
        "    df.to_csv(file_path, index=False)\n",
        "    return file_path\n",
        "\n",
        "def generate_dataset(user_input, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_MESSAGE}]\n",
        "    for msg in history:\n",
        "        messages.append(msg)\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(\"cuda\")\n",
        "    streamer = TextIteratorStreamer(tokenizer, timeout=10., skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "    generate_kwargs = dict(input_ids=inputs, streamer=streamer, max_new_tokens=2000)\n",
        "\n",
        "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
        "    t.start()\n",
        "\n",
        "    history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    history.append({\"role\": \"assistant\", \"content\": \"\"})\n",
        "\n",
        "    partial_text = \"\"\n",
        "    for new_text in streamer:\n",
        "        partial_text += new_text\n",
        "        history[-1][\"content\"] = partial_text\n",
        "        yield history, gr.update(visible=False) # Hide download button while generating\n",
        "\n",
        "    # Once finished, show the download button\n",
        "    yield history, gr.update(visible=True)\n",
        "\n",
        "# --- Gradio UI ---\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# üìä Dataset Generator with Export\")\n",
        "\n",
        "    chatbot = gr.Chatbot(label=\"Dataset Preview\", type=\"messages\", height=300)\n",
        "    msg = gr.Textbox(label=\"Input requirements\", placeholder=\"Columns: name, age. Rows: 10.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        clear = gr.Button(\"Clear Chat\")\n",
        "        # The download component\n",
        "        download_btn = gr.DownloadButton(\"Download last table as CSV (if exists)\", visible=False)\n",
        "\n",
        "    # Sequence: 1. Generate text -> 2. When done, user can click download\n",
        "    msg.submit(generate_dataset, [msg, chatbot], [chatbot, download_btn])\n",
        "    msg.submit(lambda: \"\", None, [msg])\n",
        "\n",
        "    # This function triggers when the download button is clicked\n",
        "    download_btn.click(extract_table_to_csv, [chatbot], [download_btn])\n",
        "\n",
        "    clear.click(lambda: ([], gr.update(visible=False)), None, [chatbot, download_btn])\n",
        "\n",
        "demo.launch(inbrowser=True)"
      ],
      "metadata": {
        "id": "HdQnWEzW3lzP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "0b033e8c-f743-492e-b174-621bfdaf2a7f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3355500417.py:74: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
            "/tmp/ipython-input-3355500417.py:77: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(label=\"Dataset Preview\", type=\"messages\", height=300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f5316e9896ef84cc7b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f5316e9896ef84cc7b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}